# ü§ñ AI Agent Portfolio

Welcome to the **AI Agent Portfolio**!  
This project is a modular, local-first AI agent framework designed to help you build, evaluate, and interact with AI-powered chatbots and knowledge systems. üöÄ

---

## üìö Table of Contents

- [‚ú® Features](#-features)
- [üõ†Ô∏è Technologies Used](#-technologies-used)
- [üöÄ Getting Started](#-getting-started)
- [üíª Running the Project Locally](#-running-the-project-locally)
- [üìÇ Project Structure](#-project-structure)
- [ü§î How It Works](#-how-it-works)
- [üìù License](#-license)

---

## ‚ú® Features

- Modular chat agent framework ü§ù
- RAG (Retrieval-Augmented Generation) support üìñ
- Local vector store with ChromaDB üóÉÔ∏è
- Easy-to-extend tools and controllers üõ†Ô∏è
- Knowledge base integration üß†
- Email collection and storage üìß

---

## üõ†Ô∏è Technologies Used

- **Python 3.12** üêç
- **ChromaDB** for vector storage üóÇÔ∏è
- **OpenAI / Gemini /LLM APIs** (if integrated) ü§ñ
- **LangChain** for RAG ü¶ú
- **Gradio** for UI üé®
- **NLTK** for text processing üìù
- **MongoDB** for storing user details üìù

---

## üöÄ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/ai_agent.git
cd ai_agent
```

### 2. Install Dependencies

We recommend using [uv](https://github.com/astral-sh/uv) for fast environment management and dependency installation.

1. **Install uv** (if you don't have it):

   ```bash
   brew install uv
   ```

2. **Create a virtual environment:**

   ```bash
   uv venv .venv
   ```

3. **Activate the environment:**

   - On macOS/Linux:
     ```bash
     source .venv/bin/activate
     ```

4. **Install all dependencies:**

   ```bash
   uv pip install -r requirements.txt
   ```

   Or, if you use `pyproject.toml`:

   ```bash
   uv sync .
   ```

---

## üìö Create Knowledge Base

1. Create a new folder in the `knowledge` directory.
2. Create new files in the folder.
3. Add the content of the file to the knowledge base.

## üíª Running the Project Locally

### Run the Main Application

```bash
python main.py
```

- The main entry point is `main.py`.

### Environment Variables

- You will need to set the following environment variables:

- `OPENAI_API_KEY`
- `GEMINI_API_KEY`
- `MONGO_URI`
- `MONGO_DB_CLIENT`
- `MONGO_DB_COLLECTION`

If you want to deploy in huggingface, you will need to set the following environment variables:

- `HF_TOKEN`

---

## üìÇ Project Structure

```
ai_agent/
  ‚îú‚îÄ‚îÄ app/                # Setup of gradio UI
  ‚îú‚îÄ‚îÄ chat/               # Chat agent, RAG, tools, and evaluation modules
  ‚îú‚îÄ‚îÄ chroma_store/       # Local vector database (ChromaDB)
  ‚îú‚îÄ‚îÄ knowledge/          # Knowledge base files (txt)
  ‚îú‚îÄ‚îÄ main.py             # Project entry point
  ‚îú‚îÄ‚îÄ requirements.txt    # Python dependencies
  ‚îî‚îÄ‚îÄ pyproject.toml      # Project metadata
```

---

## ü§î How It Works

1. **Knowledge Ingestion:**  
   The system loads knowledge from text files and stores embeddings in ChromaDB.

2. **Chat & RAG:**  
   The chat agent uses retrieval-augmented generation to answer questions, pulling relevant context from the knowledge base.

3. **Extensible Tools:**  
   Easily add new tools or evaluators in the `chat/` directory to expand your agent‚Äôs capabilities.

---

## üìù License

MIT License.  
Feel free to use, modify, and share! üåü

---

> Made with ‚ù§Ô∏è by Diego Araque
